# SPDX-FileCopyrightText: Copyright (c) 2024-2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


general:
  use_uvloop: true


retrievers:
  ong_retriever:
    _type: milvus_retriever
    uri: http://localhost:19530
    collection_name: "ong_docs_multilingual_embedder"
    embedding_model: milvus_embedder
    top_k: 2

functions:
  ong_retriever_tool:
    _type: aiq_retriever
    retriever: ong_retriever
    topic: Retrieve documentation for a list of hate and discrimination crimes
  

llms:
  nim_llm:
    _type: nim
    model_name: meta/llama-3.1-70b-instruct
    temperature: 0.0
  nim_rag_eval_llm:
    _type: nim
    model_name: meta/llama-3.1-70b-instruct
    max_tokens: 8
  nim_trajectory_eval_llm:
    _type: nim
    model_name: meta/llama-3.1-70b-instruct
    temperature: 0.0
    max_tokens: 1024

embedders:
  milvus_embedder:
    _type: nim
    # model_name: nvidia/nv-embedqa-e5-v5
    model_name: nvidia/llama-3.2-nv-embedqa-1b-v2
    truncate: "END"

workflow:
  _type: react_agent
  tool_names: 
  - ong_retriever_tool
  llm_name: nim_llm
  verbose: true
  retry_parsing_errors: true
  max_retries: 3
  system_prompt: |
    You are a legal assistant specialized in Spanish criminal law, assisting a judge. The user will ask you questions based on court rulings extracted from legal summaries (“cápsulas informativas”).

    Use only the information provided in the context to answer — do not make up facts. If the answer is not in the context, respond: "No se menciona en el documento."

    Respond clearly, concisely, and precisely, using formal but accessible legal language, as a legal expert would. Do not include opinions or speculation.

    You may ask the user to use the following tools:

    {tools}

    You may respond in one of two formats.
    Use the following format exactly to ask the human to use a tool:

    Question: the input question you must answer
    Thought: you should always think about what to do
    Action: the action to take, should be one of [{tool_names}]
    Action Input: the input to the action (if there is no required input, include "Action Input: None")
    Observation: wait for the human to respond with the result from the tool, do not assume the response

    ... (this Thought/Action/Action Input/Observation can repeat N times. If you do not need to use a tool, or after asking the human to use any tools and waiting for the human to respond, you might know the final answer.)
    Use the following format once you have the final answer:

    Thought: I now know the final answer
    Final Answer: the final answer to the original input question

eval:
  general:
    output:
      dir: ./.tmp/aiq/examples/simple_rag/
      cleanup: true
    dataset:
      _type: json
      file_path: examples/simple_rag/eval_data/3rd.json
    profiler:
      # Compute inter query token uniqueness
      token_uniqueness_forecast: true
      # Compute expected workflow runtime
      workflow_runtime_forecast: true
      # Compute inference optimization metrics
      compute_llm_metrics: true
      # Avoid dumping large text into the output CSV (helpful to not break structure)
      csv_exclude_io_text: true
      # Idenitfy common prompt prefixes
      prompt_caching_prefixes:
        enable: true
        min_frequency: 0.1
      bottleneck_analysis:
        # Can also be simple_stack
        enable_nested_stack: true
      concurrency_spike_analysis:
        enable: true
        spike_threshold: 7

  evaluators:
    rag_accuracy:
      _type: ragas
      metric: AnswerAccuracy
      llm_name: nim_rag_eval_llm
    rag_groundedness:
      _type: ragas
      metric: ResponseGroundedness
      llm_name: nim_rag_eval_llm
    rag_relevance:
      _type: ragas
      metric: ContextRelevance
      llm_name: nim_rag_eval_llm
    trajectory_accuracy:
      _type: trajectory
      llm_name: nim_trajectory_eval_llm
